{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init & Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#when you extract dataSet, plz make cycle one by one, assuring validation set has all 3 labels\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\" # or 0 1 to use GPU\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.classification import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "# sess = tf.Session(config=tf.ConfigProto(device_count={'gpu':0}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('trainall_data.csv', header=None) #pandas is easy to watch variables\n",
    "label=pd.read_csv('trainall_label.csv', header=None)\n",
    "tt=pd.read_csv('trainall_label2.csv', header=None)\n",
    "trainn=train.loc[:, 0:15]\n",
    "train1=trainn.values\n",
    "label1=label.values\n",
    "labell=tt.values\n",
    "\n",
    "# print trainn.describe()\n",
    "# print label.describe()\n",
    "# print tt.describe()\n",
    "\n",
    "# print label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1435, 4, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint,shuffle\n",
    "\n",
    "X2= []\n",
    "label2= []\n",
    "random_fetch=range(1435)\n",
    "shuffle(random_fetch)\n",
    "\n",
    "\n",
    "for i in range(1435):\n",
    "    X2.append(np.reshape(train1[random_fetch[i]],(4,4)))\n",
    "    label2.append(label1[random_fetch[i]])\n",
    "        \n",
    "X2=np.array(X2)\n",
    "label2=np.array(label2)\n",
    "\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Part, haven't shuffled yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64,\n",
    "                        #input_shape=(41000,),\n",
    "                        activation=tf.nn.relu), # in hidden layer, ReLU has better learning ability than sigmoid\n",
    "  tf.keras.layers.Dropout(0.2), # drop out some complex neurons randomly, avoiding overfitting\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(5, activation=tf.nn.sigmoid) #logistic output for each gas element, H2/H2O/METH/ETH/ACE\n",
    "])\n",
    "\n",
    "#todo test all optimizer\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     #optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "#                 #loss=tf.keras.losses.categorical_crossentropy,\n",
    "#                 loss='sparse_categorical_crossentropy',\n",
    "#                 #loss=tf.losses.softmax_cross_entropy,\n",
    "#                 # pred=tf.nn.softmax(tf.add(tf.matmul(X1,W),b)) ,\n",
    "#                 # cost =tf.reduce_mean(-tf.reduce_sum(label1*tf.log(pred),reduction_indices=1)),\n",
    "#                 #loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "    #optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "                #loss=tf.keras.losses.categorical_crossentropy,\n",
    "                #loss='sparse_categorical_crossentropy',\n",
    "    \n",
    "                loss='binary_crossentropy', #set loss as binary for logistic regression\n",
    "    \n",
    "                #loss=tf.losses.softmax_cross_entropy,\n",
    "                # pred=tf.nn.softmax(tf.add(tf.matmul(X1,W),b)) ,\n",
    "                # cost =tf.reduce_mean(-tf.reduce_sum(label1*tf.log(pred),reduction_indices=1)),\n",
    "                #loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME = \"enose-64*2-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1358   53   44 ... 1391  506   41]\n",
      "Train on 1291 samples, validate on 144 samples\n",
      "Epoch 1/50\n",
      "1291/1291 [==============================] - 0s 265us/step - loss: 0.4189 - acc: 0.8113 - val_loss: 0.3872 - val_acc: 0.7958\n",
      "Epoch 2/50\n",
      "1291/1291 [==============================] - 0s 72us/step - loss: 0.3574 - acc: 0.8217 - val_loss: 0.3430 - val_acc: 0.8111\n",
      "Epoch 3/50\n",
      "1291/1291 [==============================] - 0s 79us/step - loss: 0.3262 - acc: 0.8333 - val_loss: 0.3139 - val_acc: 0.8097\n",
      "Epoch 4/50\n",
      "1291/1291 [==============================] - 0s 89us/step - loss: 0.2942 - acc: 0.8517 - val_loss: 0.2853 - val_acc: 0.8514\n",
      "Epoch 5/50\n",
      "1291/1291 [==============================] - 0s 93us/step - loss: 0.2739 - acc: 0.8665 - val_loss: 0.2686 - val_acc: 0.8583\n",
      "Epoch 6/50\n",
      "1291/1291 [==============================] - 0s 77us/step - loss: 0.2555 - acc: 0.8710 - val_loss: 0.2529 - val_acc: 0.8653\n",
      "Epoch 7/50\n",
      "1291/1291 [==============================] - 0s 89us/step - loss: 0.2429 - acc: 0.8767 - val_loss: 0.2470 - val_acc: 0.8639\n",
      "Epoch 8/50\n",
      "1291/1291 [==============================] - 0s 81us/step - loss: 0.2355 - acc: 0.8804 - val_loss: 0.2395 - val_acc: 0.8653\n",
      "Epoch 9/50\n",
      "1291/1291 [==============================] - 0s 84us/step - loss: 0.2292 - acc: 0.8840 - val_loss: 0.2410 - val_acc: 0.8653\n",
      "Epoch 10/50\n",
      "1291/1291 [==============================] - 0s 87us/step - loss: 0.2229 - acc: 0.8864 - val_loss: 0.2468 - val_acc: 0.8542\n",
      "Epoch 11/50\n",
      "1291/1291 [==============================] - 0s 81us/step - loss: 0.2185 - acc: 0.8871 - val_loss: 0.2354 - val_acc: 0.8611\n",
      "Epoch 12/50\n",
      "1291/1291 [==============================] - 0s 83us/step - loss: 0.2125 - acc: 0.8881 - val_loss: 0.2168 - val_acc: 0.8764\n",
      "Epoch 13/50\n",
      "1291/1291 [==============================] - 0s 83us/step - loss: 0.2075 - acc: 0.8900 - val_loss: 0.2184 - val_acc: 0.8736\n",
      "Epoch 14/50\n",
      "1291/1291 [==============================] - 0s 92us/step - loss: 0.2037 - acc: 0.8911 - val_loss: 0.2116 - val_acc: 0.8764\n",
      "Epoch 15/50\n",
      "1291/1291 [==============================] - 0s 87us/step - loss: 0.1981 - acc: 0.8942 - val_loss: 0.2079 - val_acc: 0.8778\n",
      "Epoch 16/50\n",
      "1291/1291 [==============================] - 0s 78us/step - loss: 0.1953 - acc: 0.8960 - val_loss: 0.2170 - val_acc: 0.8722\n",
      "Epoch 17/50\n",
      "1291/1291 [==============================] - 0s 90us/step - loss: 0.1938 - acc: 0.8965 - val_loss: 0.1943 - val_acc: 0.8944\n",
      "Epoch 18/50\n",
      "1291/1291 [==============================] - 0s 101us/step - loss: 0.1859 - acc: 0.9027 - val_loss: 0.1977 - val_acc: 0.8847\n",
      "Epoch 19/50\n",
      "1291/1291 [==============================] - 0s 87us/step - loss: 0.1836 - acc: 0.9030 - val_loss: 0.2003 - val_acc: 0.8806\n",
      "Epoch 20/50\n",
      "1291/1291 [==============================] - 0s 83us/step - loss: 0.1791 - acc: 0.9074 - val_loss: 0.1879 - val_acc: 0.8889\n",
      "Epoch 21/50\n",
      "1291/1291 [==============================] - 0s 87us/step - loss: 0.1722 - acc: 0.9097 - val_loss: 0.1805 - val_acc: 0.9028\n",
      "Epoch 22/50\n",
      "1291/1291 [==============================] - 0s 95us/step - loss: 0.1819 - acc: 0.9067 - val_loss: 0.1898 - val_acc: 0.8931\n",
      "Epoch 23/50\n",
      "1291/1291 [==============================] - 0s 88us/step - loss: 0.1759 - acc: 0.9067 - val_loss: 0.2277 - val_acc: 0.8736\n",
      "Epoch 24/50\n",
      "1291/1291 [==============================] - 0s 88us/step - loss: 0.1739 - acc: 0.9075 - val_loss: 0.1747 - val_acc: 0.9194\n",
      "Epoch 25/50\n",
      "1291/1291 [==============================] - 0s 90us/step - loss: 0.1764 - acc: 0.9117 - val_loss: 0.1755 - val_acc: 0.9167\n",
      "Epoch 26/50\n",
      "1291/1291 [==============================] - 0s 99us/step - loss: 0.1742 - acc: 0.9129 - val_loss: 0.1682 - val_acc: 0.9222\n",
      "Epoch 27/50\n",
      "1291/1291 [==============================] - 0s 98us/step - loss: 0.1686 - acc: 0.9160 - val_loss: 0.1711 - val_acc: 0.9181\n",
      "Epoch 28/50\n",
      "1291/1291 [==============================] - 0s 68us/step - loss: 0.1591 - acc: 0.9222 - val_loss: 0.1509 - val_acc: 0.9347\n",
      "Epoch 29/50\n",
      "1291/1291 [==============================] - 0s 87us/step - loss: 0.1529 - acc: 0.9250 - val_loss: 0.1570 - val_acc: 0.9306\n",
      "Epoch 30/50\n",
      "1291/1291 [==============================] - 0s 86us/step - loss: 0.1587 - acc: 0.9229 - val_loss: 0.1781 - val_acc: 0.9083\n",
      "Epoch 31/50\n",
      "1291/1291 [==============================] - 0s 88us/step - loss: 0.1565 - acc: 0.9244 - val_loss: 0.1660 - val_acc: 0.9125\n",
      "Epoch 32/50\n",
      "1291/1291 [==============================] - 0s 81us/step - loss: 0.1424 - acc: 0.9345 - val_loss: 0.1451 - val_acc: 0.9389\n",
      "Epoch 33/50\n",
      "1291/1291 [==============================] - 0s 89us/step - loss: 0.1473 - acc: 0.9295 - val_loss: 0.1526 - val_acc: 0.9319\n",
      "Epoch 34/50\n",
      "1291/1291 [==============================] - 0s 89us/step - loss: 0.1439 - acc: 0.9332 - val_loss: 0.1561 - val_acc: 0.9208\n",
      "Epoch 35/50\n",
      "1291/1291 [==============================] - 0s 90us/step - loss: 0.1439 - acc: 0.9304 - val_loss: 0.1404 - val_acc: 0.9375\n",
      "Epoch 36/50\n",
      "1291/1291 [==============================] - 0s 90us/step - loss: 0.1425 - acc: 0.9312 - val_loss: 0.1472 - val_acc: 0.9319\n",
      "Epoch 37/50\n",
      "1291/1291 [==============================] - 0s 90us/step - loss: 0.1334 - acc: 0.9397 - val_loss: 0.1335 - val_acc: 0.9458\n",
      "Epoch 38/50\n",
      "1291/1291 [==============================] - 0s 84us/step - loss: 0.1384 - acc: 0.9357 - val_loss: 0.1332 - val_acc: 0.9389\n",
      "Epoch 39/50\n",
      "1291/1291 [==============================] - 0s 82us/step - loss: 0.1364 - acc: 0.9363 - val_loss: 0.1336 - val_acc: 0.9389\n",
      "Epoch 40/50\n",
      "1291/1291 [==============================] - 0s 97us/step - loss: 0.1303 - acc: 0.9425 - val_loss: 0.1380 - val_acc: 0.9458\n",
      "Epoch 41/50\n",
      "1291/1291 [==============================] - 0s 84us/step - loss: 0.1284 - acc: 0.9407 - val_loss: 0.1326 - val_acc: 0.9403\n",
      "Epoch 42/50\n",
      "1291/1291 [==============================] - 0s 84us/step - loss: 0.1255 - acc: 0.9435 - val_loss: 0.1696 - val_acc: 0.9278\n",
      "Epoch 43/50\n",
      "1291/1291 [==============================] - 0s 89us/step - loss: 0.1267 - acc: 0.9418 - val_loss: 0.1294 - val_acc: 0.9444\n",
      "Epoch 44/50\n",
      "1291/1291 [==============================] - 0s 81us/step - loss: 0.1208 - acc: 0.9436 - val_loss: 0.1412 - val_acc: 0.9375\n",
      "Epoch 45/50\n",
      "1291/1291 [==============================] - 0s 77us/step - loss: 0.1293 - acc: 0.9382 - val_loss: 0.1462 - val_acc: 0.9389\n",
      "Epoch 46/50\n",
      "1291/1291 [==============================] - 0s 92us/step - loss: 0.1263 - acc: 0.9436 - val_loss: 0.1266 - val_acc: 0.9431\n",
      "Epoch 47/50\n",
      "1291/1291 [==============================] - 0s 83us/step - loss: 0.1097 - acc: 0.9529 - val_loss: 0.1243 - val_acc: 0.9486\n",
      "Epoch 48/50\n",
      "1291/1291 [==============================] - 0s 83us/step - loss: 0.1194 - acc: 0.9456 - val_loss: 0.1260 - val_acc: 0.9444\n",
      "Epoch 49/50\n",
      "1291/1291 [==============================] - 0s 87us/step - loss: 0.1108 - acc: 0.9506 - val_loss: 0.1182 - val_acc: 0.9486\n",
      "Epoch 50/50\n",
      "1291/1291 [==============================] - 0s 79us/step - loss: 0.1077 - acc: 0.9510 - val_loss: 0.1312 - val_acc: 0.9486\n",
      "1435/1435 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11231576739080276, 0.9560975613909731]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X1=np.tile(X_train,(100,1,1))\n",
    "#label1=np.tile(label,(100,1))\n",
    "\n",
    "## if run 1110 samples, make sure the input labels are correct and not modified\n",
    "\n",
    "# gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "from random import randint,shuffle\n",
    "\n",
    "X2= []\n",
    "label2= []\n",
    "random_fetch=range(1435)\n",
    "shuffle(random_fetch)\n",
    "\n",
    "\n",
    "for i in range(1435):\n",
    "    X2.append(np.reshape(train1[random_fetch[i]],(4,4)))\n",
    "    label2.append(labell[random_fetch[i]])\n",
    "        \n",
    "X2=np.array(X2)\n",
    "label2=np.array(label2)\n",
    "\n",
    "np.set_printoptions(threshold=10)\n",
    "random_fetch=np.array(random_fetch)\n",
    "print(random_fetch)\n",
    "model.fit(X2, label2, batch_size=20, validation_split=0.1, epochs=50, shuffle=0, callbacks=[tensorboard]) # this shuffle for each epochs, we dont wantit\n",
    "model.evaluate(X2,label2)\n",
    "\n",
    "# print label1[368:409]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Confusion matrix, without normalization\n",
      "[[13  0  0]\n",
      " [ 0 10  6]\n",
      " [ 0  0  9]]\n",
      "Normalized confusion matrix\n",
      "[[1.   0.   0.  ]\n",
      " [0.   0.62 0.38]\n",
      " [0.   0.   1.  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAEYCAYAAAAtTS8wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW54AnXNlyxOgc65s/X/ETS/696pO4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd4c180a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAEYCAYAAADGepQzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD4bOOQd4MHTOOQD+HyUpmIc4HGFOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd4c1503d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#plot\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint,shuffle #cnn\n",
    "X2= []\n",
    "label2= []\n",
    "random_fetch=range(1435)\n",
    "shuffle(random_fetch)\n",
    "\n",
    "for i in range(1435):\n",
    "    X2.append(np.reshape(train1[random_fetch[i]],(4,4)))\n",
    "    label2.append(labell[random_fetch[i]])\n",
    "        \n",
    "X2=np.array(X2)\n",
    "label2=np.array(label2)\n",
    "trainn=X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1435, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=trainn\n",
    "y_train=label2\n",
    "# x_train = x_train.astype(np.float32) / 255\n",
    "x_train=x_train.astype(np.float32)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "# y_train = tf.one_hot(y_train, 1)\n",
    "# y_train=label\n",
    "# x_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 5)\n",
      "(1435, 4, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(threshold='none')\n",
    "test_labels = label2[1291:1435,:]\n",
    "rounded_predictions = model.predict(X2[1291:1435,:])\n",
    "# print test_labels\n",
    "print rounded_predictions.shape\n",
    "print (X2.shape)\n",
    "len(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold='none')\n",
    "test_labels = label2[1291:1435,:]\n",
    "rounded_predictions = model.predict(X2[1291:1435,:])\n",
    "# print test_labels\n",
    "print rounded_predictions.shape\n",
    "len(rounded_predictions)\n",
    "\n",
    "trans_predictions=np.zeros((144,5),dtype=int)\n",
    "\n",
    "for i in range(len(rounded_predictions)): # i, the num of stages\n",
    "    for t in range(5):\n",
    "        if rounded_predictions[i,t]>=0.5:\n",
    "            trans_predictions[i,t]=1\n",
    "            \n",
    "    if list(trans_predictions[i,:])==[0,0,0,0,0]:\n",
    "        for t in range(5):\n",
    "            if rounded_predictions[i,t]>=0.4:\n",
    "                trans_predictions[i,t]=1\n",
    "                \n",
    "#         else trans_perdictions(i,t)=0\n",
    "print trans_predictions.shape\n",
    "\n",
    "MCM = np.zeros((5,5),dtype=int)\n",
    "for i in range(len(rounded_predictions)):\n",
    "#     if list(trans_predictions[i,:])==[0,0,0,0,0]:\n",
    "#         pre_error=list(rounded_predictions[i,:])\n",
    "#         raise ValueError(\"Model prediction comes up with error. The error num is %s, with rounded as %s\" % (i,pre_error)\n",
    "#                        )\n",
    "    for t in range(5):\n",
    "        if test_labels[i,t] and trans_predictions[i,t]: #True-positive, actually for multiple class there are no po/ne\n",
    "            MCM[t,t]=MCM[t,t]+1\n",
    "        elif test_labels[i,t]:  # False\n",
    "            for t2 in range(5):\n",
    "                if trans_predictions[i,t2]:\n",
    "                    MCM[t,t2]=MCM[t,t2]+1  \n",
    "        \n",
    "        \n",
    "print MCM    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "gas_names=np.array(['H2','H2O','Methanol','Ethanol','Acetone'])\n",
    "plt.figure()\n",
    "plot_confusion_matrix(MCM, classes=gas_names,\n",
    "                     title='MCM without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print trans_predictions[29,:]\n",
    "print rounded_predictions[29,:]\n",
    "# print trans_predictions\n",
    "print test_labels[29,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard logdir='/home/hzy/MLP Test3.py'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try CNN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "if K.backend() != 'tensorflow':\n",
    "    raise RuntimeError('This example can only run with the TensorFlow backend,'\n",
    "                       ' because it requires the Datset API, which is not'\n",
    "                       ' supported on other platforms.')\n",
    "\n",
    "\n",
    "def cnn_layers(inputs):\n",
    "    x = layers.Conv2D(32, (3, 3),\n",
    "                      activation='relu', padding='valid')(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    predictions = layers.Dense(num_classes,\n",
    "                               activation='sigmoid',\n",
    "                               name='x_train_out')(x)\n",
    "    return predictions\n",
    "\n",
    "SIZE = (4,4)\n",
    "\n",
    "batch_size = 24\n",
    "buffer_size = 100\n",
    "steps_per_epoch = int(np.ceil(1435 / float(batch_size)))  # = 469\n",
    "epochs = 5\n",
    "num_classes = 5\n",
    "#Create the dataset and its associated one-shot iterator\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.shuffle(buffer_size)\n",
    "dataset = dataset.batch(batch_size)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "# Model creation using tensors from the get_next() graph node.\n",
    "inputs, targets = iterator.get_next()\n",
    "model_input = tensorflow.keras.layers.Input(tensor=inputs)\n",
    "model_output = cnn_layers(model_input)\n",
    "train_model = keras.models.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "train_model.compile(optimizer=keras.optimizers.RMSprop(lr=2e-3, decay=1e-5),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'],\n",
    "                    target_tensors=[targets])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(trans_predictions[3,:])\n",
    "# np.array([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_predictions=np.zeros((143,5),dtype=int)\n",
    "trans_predictions\n",
    "len(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Sequence\n",
    "from scipy.sparse.base import spmatrix\n",
    "\n",
    "cm = multilabel_confusion_matrix(test_labels,rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print label2[18]\n",
    "X2.shape\n",
    "test=np.reshape(X2[18],[1,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Appently, the data performance between meth part, ace part and eth part are not that good, i.e. if we use single raw data set extracting from a single experience. The performance would be great (shown as below) because of the data correlation and sigularity. \n",
    "\n",
    "### In a word, we can not determine if the data presented from our experiments can differ from each other that well. That is a very significant prerequsite. Assuming there are better network structure to explore, I think we can enhance this MLP with the following aspects.\n",
    "\n",
    "## 1. More reasonable normalization method. Maybe instead of using the last time point, there are better solution.\n",
    "## 2. Adding more layers as well as tuning parameters for better performance. \n",
    "## 3. When we do shuffling, try to use random search instead of grid seach.\n",
    "## 4. Increasing the number of samples in trainingSet, however it has been experienced before and it was not that effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_a=np.reshape(X1[410:820,:,:],[410,16]) # acetone\n",
    "label_a=label1[410:820]\n",
    "train_vi=pd.DataFrame(train_a)\n",
    "train_vi.describe()\n",
    "print label_a\n",
    "import matplotlib.pyplot as plt\n",
    "train_vi.plot(kind='scatter',x=2,y=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_a=X1[410:820,:,:] # acetone\n",
    "label_a=label1[410:820]\n",
    "# print train_a\n",
    "# print label_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold='none')\n",
    "print train_a.shape\n",
    "print label_a.shape\n",
    "print label_a #acetone\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=range(10)\n",
    "shuffle(a)\n",
    "print a\n",
    "np.set_printoptions(threshold='none')\n",
    "label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffling the cycles for 410,acetone\n",
    "\n",
    "from random import randint,shuffle\n",
    "train_a=X1[410:820,:,:] # acetone\n",
    "label_a=label1[410:820]\n",
    "\n",
    "X2= []\n",
    "label2= []\n",
    "random_fetch=range(10)\n",
    "shuffle(random_fetch)\n",
    "train_ace=X1\n",
    "\n",
    "for i in range(10):\n",
    "    for k in range(41):\n",
    "        X2.append(np.reshape(train_a[random_fetch[i]*41+k],(4,4)))\n",
    "        label2.append(label_a[random_fetch[i]*41+k])   \n",
    "    \n",
    "X2=np.array(X2)\n",
    "label2=np.array(label2)\n",
    "\n",
    "\n",
    "print random_fetch\n",
    "np.set_printoptions(threshold=3)\n",
    "print X2\n",
    "print label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tess=np.array([[1,2,3],[4,5,6]])\n",
    "t=np.tile(tess,(2,1))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold='none')\n",
    "print label_a\n",
    "train_sub=train_a[0:369,:,:]\n",
    "label_sub=label_a[0:369]  \n",
    "print label_a[409]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "from random import randint,shuffle\n",
    "\n",
    "train_a=X2\n",
    "label_a=label2\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64,\n",
    "                        #input_shape=(41000,),\n",
    "                        activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "for i in range(410):\n",
    "    if label_a[i]==3:\n",
    "        label_a[i]=1\n",
    "    elif label_a[i]==4:\n",
    "        label_a[i]=2\n",
    "\n",
    "# tiling the data\n",
    "train_sub=train_a[0:369,:,:]\n",
    "train_lab=label_a[0:369]\n",
    "valid_sub=train_a[369:410,:,:]\n",
    "valid_lab=label_a[369:410]\n",
    "m1=np.tile(train_sub,(100,1,1))\n",
    "m2=np.tile(valid_sub,(100,1,1))\n",
    "m3=np.tile(train_lab,(100,))\n",
    "m4=np.tile(valid_lab,(100,))\n",
    "label_input=np.concatenate([m3,m4])\n",
    "train_input=np.concatenate([m1,m2])\n",
    "\n",
    "train_input1=np.tile(train_a,(100,1,1))\n",
    "label_input1=np.tile(label_a,(100,))\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold='none')\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    #optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True),\n",
    "                #loss=tf.keras.losses.categorical_crossentropy,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                #loss=tf.losses.softmax_cross_entropy,\n",
    "                # pred=tf.nn.softmax(tf.add(tf.matmul(X1,W),b)) ,\n",
    "                # cost =tf.reduce_mean(-tf.reduce_sum(label1*tf.log(pred),reduction_indices=1)),\n",
    "                #loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_input, label_input, validation_split=0.1, epochs=5)\n",
    "model.evaluate(train_input,label_input)\n",
    "\n",
    "# print label1[368:409]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_a.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tess=[]\n",
    "tess=np.array(tess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "#print sess.run(model.fit)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=np.reshape(X1[399],(1,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold='none')\n",
    "#label1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label1[399]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model.predict(test,batch_size=10,verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model.predict_classes(test,batch_size=10,verbose=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
